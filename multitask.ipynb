{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38ebedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269b3fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[i for i in df.columns if i not in ['index','rdkit_smi'] and 'pIC50' not in i]]\n",
    "y = df[['herg_pIC50', 'hepg2_pIC50', 'cyp1_pIC50','cyp2_pIC50', 'cyp3_pIC50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28fbc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/YyzHarry/imbalanced-regression\n",
    "# sts-b-dir 폴더 git clone 하기!\n",
    "# sts-b-dir 폴더 내에 util.py가 있는데 이거 이름을 utils.py로 바꿔야 밑에 함수가 불러와짐\n",
    "import sys\n",
    "from collections import Counter\n",
    "from scipy.ndimage import convolve1d\n",
    "\n",
    "sys.path.append(r'D:\\\\toxic_prediction\\\\sts-b-dir') # LDS를 위한 함수를 불러오기 위해서\n",
    "\n",
    "from utils import get_lds_kernel_window\n",
    "\n",
    "def get_bin_idx(label, num_bins, label_min, label_max):\n",
    "    if label_max == label_min:\n",
    "        return 0\n",
    "    \n",
    "    normalized = (label - label_min) / (label_max - label_min)\n",
    "    bin_idx = int(normalized * num_bins)   \n",
    "    return max(0, min(num_bins - 1, bin_idx))\n",
    "\n",
    "def lds(labels):\n",
    "    # preds, labels: [Ns,], \"Ns\" is the number of total samples\n",
    "    # assign each label to its corresponding bin (start from 0)\n",
    "    # with your defined get_bin_idx(), return bin_index_per_label: [Ns,] \n",
    "    label_min = min(labels)\n",
    "    label_max = max(labels)\n",
    "    num_bins = 50\n",
    "\n",
    "    bin_index_per_label = [get_bin_idx(label, num_bins, label_min, label_max) for label in labels]\n",
    "\n",
    "    # calculate empirical (original) label distribution: [Nb,]\n",
    "    # \"Nb\" is the number of bins\n",
    "    Nb = max(bin_index_per_label) + 1\n",
    "    num_samples_of_bins = dict(Counter(bin_index_per_label))\n",
    "    emp_label_dist = [num_samples_of_bins.get(i, 0) for i in range(Nb)]\n",
    "\n",
    "    # lds_kernel_window: [ks,], here for example, we use gaussian, ks=5, sigma=2\n",
    "    lds_kernel_window = get_lds_kernel_window(kernel='gaussian', ks=5, sigma=2)\n",
    "    # calculate effective label distribution: [Nb,]\n",
    "    eff_label_dist = convolve1d(np.array(emp_label_dist), weights=lds_kernel_window, mode='constant')\n",
    "\n",
    "    # Use re-weighting based on effective label distribution, sample-wise weights: [Ns,]\n",
    "    eff_num_per_label = [eff_label_dist[bin_idx] for bin_idx in bin_index_per_label]\n",
    "    lds_pIC50 = [np.float32(1 / x) for x in eff_num_per_label]\n",
    "    lds_pIC50 = lds_pIC50 / np.mean(lds_pIC50) # 원본 코드에는 이게 없는데 이렇게 해야 가중치 간 값의 차이가 좀 생김\n",
    "    # 이거 안하면 0.62, 0.0054 이런식이라 모델이 제대로 가중치 적용을 못하는듯 하여 이렇게 한 줄 추가함\n",
    "\n",
    "    return lds_pIC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d627124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.999)  \n",
    "df_pca = pca.fit_transform(x)\n",
    "df_pca = pd.DataFrame(df_pca).reset_index(drop=True)\n",
    "df_pca.columns = ['pca' + str(i) for i in df_pca.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "befc7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = ['herg_pIC50', 'hepg2_pIC50', 'cyp1_pIC50','cyp2_pIC50', 'cyp3_pIC50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fe90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[176.16484296,  35.0548407 ,  57.09000136]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_linnerud\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "regr = MultiOutputRegressor(Ridge(random_state=123)).fit(df_pca, df[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c707f651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>herg_pIC50</th>\n",
       "      <th>hepg2_pIC50</th>\n",
       "      <th>cyp1_pIC50</th>\n",
       "      <th>cyp2_pIC50</th>\n",
       "      <th>cyp3_pIC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.158943</td>\n",
       "      <td>-4.082785</td>\n",
       "      <td>-3.805099</td>\n",
       "      <td>-3.095509</td>\n",
       "      <td>-3.688620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.227800</td>\n",
       "      <td>-4.190332</td>\n",
       "      <td>-3.925421</td>\n",
       "      <td>-3.002700</td>\n",
       "      <td>-3.768460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.124063</td>\n",
       "      <td>-4.910000</td>\n",
       "      <td>-3.928708</td>\n",
       "      <td>-3.966669</td>\n",
       "      <td>-4.088627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.273625</td>\n",
       "      <td>-4.480000</td>\n",
       "      <td>-3.801309</td>\n",
       "      <td>-3.237118</td>\n",
       "      <td>-4.538229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.891140</td>\n",
       "      <td>-4.640000</td>\n",
       "      <td>-3.682381</td>\n",
       "      <td>-3.217334</td>\n",
       "      <td>-3.889728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44414</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-3.409001</td>\n",
       "      <td>-4.477121</td>\n",
       "      <td>-4.477121</td>\n",
       "      <td>-4.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44415</th>\n",
       "      <td>-3.805735</td>\n",
       "      <td>-3.980368</td>\n",
       "      <td>-4.823700</td>\n",
       "      <td>-3.570359</td>\n",
       "      <td>-4.146392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44416</th>\n",
       "      <td>-3.921612</td>\n",
       "      <td>-3.774654</td>\n",
       "      <td>-4.030989</td>\n",
       "      <td>-3.602060</td>\n",
       "      <td>-3.110931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44417</th>\n",
       "      <td>-4.367977</td>\n",
       "      <td>-3.723841</td>\n",
       "      <td>-4.053462</td>\n",
       "      <td>-3.379220</td>\n",
       "      <td>-4.137978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44418</th>\n",
       "      <td>-4.220179</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-4.060300</td>\n",
       "      <td>-3.725545</td>\n",
       "      <td>-4.621081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44419 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       herg_pIC50  hepg2_pIC50  cyp1_pIC50  cyp2_pIC50  cyp3_pIC50\n",
       "0       -3.158943    -4.082785   -3.805099   -3.095509   -3.688620\n",
       "1       -3.227800    -4.190332   -3.925421   -3.002700   -3.768460\n",
       "2       -3.124063    -4.910000   -3.928708   -3.966669   -4.088627\n",
       "3       -3.273625    -4.480000   -3.801309   -3.237118   -4.538229\n",
       "4       -3.891140    -4.640000   -3.682381   -3.217334   -3.889728\n",
       "...           ...          ...         ...         ...         ...\n",
       "44414   -5.000000    -3.409001   -4.477121   -4.477121   -4.477121\n",
       "44415   -3.805735    -3.980368   -4.823700   -3.570359   -4.146392\n",
       "44416   -3.921612    -3.774654   -4.030989   -3.602060   -3.110931\n",
       "44417   -4.367977    -3.723841   -4.053462   -3.379220   -4.137978\n",
       "44418   -4.220179    -5.000000   -4.060300   -3.725545   -4.621081\n",
       "\n",
       "[44419 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "000c27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.764351\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.861830\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.895123\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.942084\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.780581\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.764040\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.860469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.895416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.941210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.780904\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.765132\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.862911\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.893675\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.941085\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.779918\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.765144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.863430\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.894079\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.942263\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.780858\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.767546\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.862061\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.896561\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.943915\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.782289\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.765497\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.860419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.894553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.941952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.780342\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.763431\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.860070\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.894256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.942111\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.778904\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.765013\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.863797\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.895222\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.942039\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.780849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.766142\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.861351\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.896180\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.943412\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39977, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.782526\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39978, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.765815\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39978, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.860359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39978, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.895630\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39978, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.942270\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 39978, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -3.780498\n",
      "각 Fold의 MSE: [0.15380571537946935, 0.15367414792653383, 0.15460562961938734, 0.15778789347984262, 0.15549991505396416, 0.14900510647033566, 0.1478920167056617, 0.15702651343918916, 0.15686096697717067, 0.15805558235966927]\n",
      "평균 MSE: 0.15442134874112237\n",
      "각 Fold의 RMSE: [0.392180717755819, 0.39201294357015026, 0.39319922382856676, 0.3972252427525756, 0.39433477535460165, 0.38601179576579736, 0.3845673110206609, 0.39626571065282595, 0.3960567724167467, 0.3975620484398244]\n",
      "평균 RMSE: 0.3929416541557569\n",
      "각 Fold의 R2: [0.6223553595641294, 0.6080459187776268, 0.6120692229731906, 0.5998802459151309, 0.6069166795292913, 0.6142462054604987, 0.6109699383908161, 0.6063822767371336, 0.6141890024102137, 0.6049578212181765]\n",
      "평균 R2: 0.6100012670976207\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LGBMRegressor(\n",
    "            random_state=42, n_estimators=500, min_child_weight=5, n_jobs=-1,\n",
    "            learning_rate = 0.05\n",
    "        )\n",
    "\n",
    "def kfold(model, X_resampled, y_resampled):\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    mse_list, rmse_list, r2_list = [], [], []\n",
    "\n",
    "    # 인덱스 리셋(정렬/정합 문제 방지)\n",
    "    Xr = X_resampled.reset_index(drop=True)\n",
    "    yr = y_resampled.reset_index(drop=True)\n",
    "    # w_all = np.asarray(lds(yr), dtype=float)  # 전체에서 만든 가중치라면\n",
    "\n",
    "    for tr_idx, te_idx in kf.split(Xr):\n",
    "        X_train, X_test = Xr.iloc[tr_idx], Xr.iloc[te_idx]\n",
    "        y_train, y_test = yr.iloc[tr_idx], yr.iloc[te_idx]\n",
    "                      \n",
    "        multi_model = MultiOutputRegressor(model)\n",
    "        multi_model.fit(X_train, y_train)\n",
    "        y_pred = multi_model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        mse_list.append(mse)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    print(\"각 Fold의 MSE:\", mse_list)\n",
    "    print(\"평균 MSE:\", np.mean(mse_list))\n",
    "    print(\"각 Fold의 RMSE:\", rmse_list)\n",
    "    print(\"평균 RMSE:\", np.mean(rmse_list))\n",
    "    print(\"각 Fold의 R2:\", r2_list)\n",
    "    print(\"평균 R2:\", np.mean(r2_list))\n",
    "\n",
    "kfold(model, df_pca, df[y_col])\n",
    "# pred = model.predict(ligand_df_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
