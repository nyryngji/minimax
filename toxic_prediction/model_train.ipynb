{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29f0c2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rdkit_smi</th>\n",
       "      <th>herg_pIC50</th>\n",
       "      <th>hepg2_pIC50</th>\n",
       "      <th>cyp1_pIC50</th>\n",
       "      <th>cyp2_pIC50</th>\n",
       "      <th>cyp3_pIC50</th>\n",
       "      <th>rdkit0</th>\n",
       "      <th>rdkit1</th>\n",
       "      <th>rdkit2</th>\n",
       "      <th>...</th>\n",
       "      <th>ChemBERTa758</th>\n",
       "      <th>ChemBERTa759</th>\n",
       "      <th>ChemBERTa760</th>\n",
       "      <th>ChemBERTa761</th>\n",
       "      <th>ChemBERTa762</th>\n",
       "      <th>ChemBERTa763</th>\n",
       "      <th>ChemBERTa764</th>\n",
       "      <th>ChemBERTa765</th>\n",
       "      <th>ChemBERTa766</th>\n",
       "      <th>ChemBERTa767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Br.CCCCOc1ccc2c3ccnc(C)c3n(CC(C)C)c2c1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.082785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.142479</td>\n",
       "      <td>-2.118959</td>\n",
       "      <td>2.328215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180178</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>-1.386276</td>\n",
       "      <td>0.212496</td>\n",
       "      <td>-0.035696</td>\n",
       "      <td>1.496147</td>\n",
       "      <td>0.087391</td>\n",
       "      <td>-0.816885</td>\n",
       "      <td>-0.166529</td>\n",
       "      <td>-0.102956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Br.CCCCOc1ccc2c3ccnc(C)c3n(CCCC)c2c1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.190332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.131358</td>\n",
       "      <td>-2.092394</td>\n",
       "      <td>2.325443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131249</td>\n",
       "      <td>-0.237652</td>\n",
       "      <td>-1.550219</td>\n",
       "      <td>0.256954</td>\n",
       "      <td>-0.175876</td>\n",
       "      <td>1.530199</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>-0.706796</td>\n",
       "      <td>0.077539</td>\n",
       "      <td>-0.224275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Br.CCCCn1c2cc(O)ccc2c2ccnc(C)c21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.910000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.124477</td>\n",
       "      <td>-2.073277</td>\n",
       "      <td>2.319935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424615</td>\n",
       "      <td>-0.148931</td>\n",
       "      <td>-1.203021</td>\n",
       "      <td>0.256493</td>\n",
       "      <td>-0.045351</td>\n",
       "      <td>1.712546</td>\n",
       "      <td>0.162551</td>\n",
       "      <td>-0.709963</td>\n",
       "      <td>0.325040</td>\n",
       "      <td>-0.077512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Br.CCCCn1c2cc(OC(C)C)ccc2c2ccnc(C)c21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.134342</td>\n",
       "      <td>-2.111540</td>\n",
       "      <td>2.326932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139105</td>\n",
       "      <td>0.165535</td>\n",
       "      <td>-1.101270</td>\n",
       "      <td>0.166301</td>\n",
       "      <td>-0.274676</td>\n",
       "      <td>1.776415</td>\n",
       "      <td>0.096857</td>\n",
       "      <td>-1.068090</td>\n",
       "      <td>0.204451</td>\n",
       "      <td>-0.077804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Br.CCCCn1c2cc(OCC)ccc2c2ccnc(C)c21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.640000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.129806</td>\n",
       "      <td>-2.085897</td>\n",
       "      <td>2.324375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197084</td>\n",
       "      <td>-0.165342</td>\n",
       "      <td>-1.175774</td>\n",
       "      <td>0.275327</td>\n",
       "      <td>-0.278163</td>\n",
       "      <td>1.767010</td>\n",
       "      <td>0.078930</td>\n",
       "      <td>-0.908876</td>\n",
       "      <td>0.130458</td>\n",
       "      <td>-0.116104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 984 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                               rdkit_smi  herg_pIC50  hepg2_pIC50  \\\n",
       "0      0  Br.CCCCOc1ccc2c3ccnc(C)c3n(CC(C)C)c2c1         NaN    -4.082785   \n",
       "1      1    Br.CCCCOc1ccc2c3ccnc(C)c3n(CCCC)c2c1         NaN    -4.190332   \n",
       "2      2        Br.CCCCn1c2cc(O)ccc2c2ccnc(C)c21         NaN    -4.910000   \n",
       "3      3   Br.CCCCn1c2cc(OC(C)C)ccc2c2ccnc(C)c21         NaN    -4.480000   \n",
       "4      4      Br.CCCCn1c2cc(OCC)ccc2c2ccnc(C)c21         NaN    -4.640000   \n",
       "\n",
       "   cyp1_pIC50  cyp2_pIC50  cyp3_pIC50    rdkit0    rdkit1    rdkit2  ...  \\\n",
       "0         NaN         NaN         NaN  2.142479 -2.118959  2.328215  ...   \n",
       "1         NaN         NaN         NaN  2.131358 -2.092394  2.325443  ...   \n",
       "2         NaN         NaN         NaN  2.124477 -2.073277  2.319935  ...   \n",
       "3         NaN         NaN         NaN  2.134342 -2.111540  2.326932  ...   \n",
       "4         NaN         NaN         NaN  2.129806 -2.085897  2.324375  ...   \n",
       "\n",
       "   ChemBERTa758  ChemBERTa759  ChemBERTa760  ChemBERTa761  ChemBERTa762  \\\n",
       "0      0.180178     -0.185827     -1.386276      0.212496     -0.035696   \n",
       "1      0.131249     -0.237652     -1.550219      0.256954     -0.175876   \n",
       "2      0.424615     -0.148931     -1.203021      0.256493     -0.045351   \n",
       "3      0.139105      0.165535     -1.101270      0.166301     -0.274676   \n",
       "4      0.197084     -0.165342     -1.175774      0.275327     -0.278163   \n",
       "\n",
       "   ChemBERTa763  ChemBERTa764  ChemBERTa765  ChemBERTa766  ChemBERTa767  \n",
       "0      1.496147      0.087391     -0.816885     -0.166529     -0.102956  \n",
       "1      1.530199      0.007508     -0.706796      0.077539     -0.224275  \n",
       "2      1.712546      0.162551     -0.709963      0.325040     -0.077512  \n",
       "3      1.776415      0.096857     -1.068090      0.204451     -0.077804  \n",
       "4      1.767010      0.078930     -0.908876      0.130458     -0.116104  \n",
       "\n",
       "[5 rows x 984 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import ImbalancedLearningRegression as iblr\n",
    "from xgboost import XGBRFRegressor, XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e21e0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import deepchem as dc\n",
    "\n",
    "# rdkit_featurizer = dc.feat.RDKitDescriptors()\n",
    "# features = rdkit_featurizer.featurize(df['rdkit_smi'])\n",
    "\n",
    "# features = pd.DataFrame(features)\n",
    "\n",
    "# features = features.reset_index(drop=True) # 분자의 화학적 특성 df\n",
    "# features.columns = ['rdkit'+str(i) for i in range(features.shape[1])]\n",
    "\n",
    "# df = df.reset_index()\n",
    "# features['rdkit_smi'] = df['rdkit_smi']\n",
    "# df = pd.merge(df,features)\n",
    "\n",
    "# featurizer = dc.feat.CircularFingerprint(size=2048, radius=4)\n",
    "# total_fp_sum = pd.DataFrame([[sum(featurizer.featurize(smiles)[0]),smiles] for smiles in df['rdkit_smi']],columns=['fp_sum','rdkit_smi'])\n",
    "\n",
    "# df = pd.merge(df,total_fp_sum)\n",
    "\n",
    "# df.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbec2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "# # ChemBERTa 모델과 토크나이저 로드\n",
    "# model_name = 'seyonec/ChemBERTa-zinc250k-v1'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# def ChemBERTa_feature(smiles):\n",
    "\n",
    "#     inputs = tokenizer(smiles, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs) #\n",
    "\n",
    "#     feature_vector = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "#     # 분자 특성 벡터 추출\n",
    "#     return list(feature_vector.reshape(-1,))\n",
    "\n",
    "# total_ChemBERTa_df = pd.DataFrame([ChemBERTa_feature(i)+[i] for i in df['rdkit_smi']])\n",
    "# total_ChemBERTa_df.columns = ['ChemBERTa' + str(i) for i in total_ChemBERTa_df.columns[:-1]] + ['rdkit_smi']\n",
    "\n",
    "# df = pd.merge(df, total_ChemBERTa_df)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "881b7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# inf, NaN, 범위 초과 모두 확인\n",
    "for_pca_df = df[[i for i in df.columns if 'pIC50' not in i and i not in ['rdkit_smi','index']]]\n",
    "for_pca_df = for_pca_df.fillna(0)\n",
    "\n",
    "# mask = (np.isinf(for_pca_df)) | (np.isnan(for_pca_df)) | (np.abs(for_pca_df) > 1e308) # inf값 존재\n",
    "# remove_idx = for_pca_df[mask.any(axis=1)].index\n",
    "\n",
    "# df = df.drop(remove_idx)\n",
    "# for_pca_df = for_pca_df.drop(remove_idx)\n",
    "for_pca_df = for_pca_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5e715c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현제 data.csv는 rdkitdescriptor, chemberta까지 끝낸상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4652c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 몇 천개의 특성을 pca로 줄임\n",
    "pca = PCA(n_components=0.999)  \n",
    "df_pca = pca.fit_transform(for_pca_df)\n",
    "\n",
    "df_pca = pd.DataFrame(df_pca).reset_index(drop=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "pIC_list = ['herg_pIC50', 'hepg2_pIC50', 'cyp1_pIC50', 'cyp2_pIC50', 'cyp3_pIC50']\n",
    "df_pca[pIC_list] = df[pIC_list]\n",
    "\n",
    "df_pca.columns = ['pca'+str(i) if '_' not in str(i) else str(i) for i in df_pca.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf8cffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/YyzHarry/imbalanced-regression\n",
    "# sts-b-dir 폴더 git clone 하기!\n",
    "# sts-b-dir 폴더 내에 util.py가 있는데 이거 이름을 utils.py로 바꿔야 밑에 함수가 불러와짐\n",
    "import sys\n",
    "from collections import Counter\n",
    "from scipy.ndimage import convolve1d\n",
    "\n",
    "sys.path.append(r'D:\\\\toxic_prediction\\\\sts-b-dir') # LDS를 위한 함수를 불러오기 위해서\n",
    "\n",
    "from utils import get_lds_kernel_window\n",
    "\n",
    "def get_bin_idx(label, num_bins, label_min, label_max):\n",
    "    if label_max == label_min:\n",
    "        return 0\n",
    "    \n",
    "    normalized = (label - label_min) / (label_max - label_min)\n",
    "    bin_idx = int(normalized * num_bins)   \n",
    "    return max(0, min(num_bins - 1, bin_idx))\n",
    "\n",
    "def lds(labels):\n",
    "    # preds, labels: [Ns,], \"Ns\" is the number of total samples\n",
    "    # assign each label to its corresponding bin (start from 0)\n",
    "    # with your defined get_bin_idx(), return bin_index_per_label: [Ns,] \n",
    "    label_min = min(labels)\n",
    "    label_max = max(labels)\n",
    "    num_bins = 50\n",
    "\n",
    "    bin_index_per_label = [get_bin_idx(label, num_bins, label_min, label_max) for label in labels]\n",
    "\n",
    "    # calculate empirical (original) label distribution: [Nb,]\n",
    "    # \"Nb\" is the number of bins\n",
    "    Nb = max(bin_index_per_label) + 1\n",
    "    num_samples_of_bins = dict(Counter(bin_index_per_label))\n",
    "    emp_label_dist = [num_samples_of_bins.get(i, 0) for i in range(Nb)]\n",
    "\n",
    "    # lds_kernel_window: [ks,], here for example, we use gaussian, ks=5, sigma=2\n",
    "    lds_kernel_window = get_lds_kernel_window(kernel='gaussian', ks=5, sigma=2)\n",
    "    # calculate effective label distribution: [Nb,]\n",
    "    eff_label_dist = convolve1d(np.array(emp_label_dist), weights=lds_kernel_window, mode='constant')\n",
    "\n",
    "    # Use re-weighting based on effective label distribution, sample-wise weights: [Ns,]\n",
    "    eff_num_per_label = [eff_label_dist[bin_idx] for bin_idx in bin_index_per_label]\n",
    "    lds_pIC50 = [np.float32(1 / x) for x in eff_num_per_label]\n",
    "    lds_pIC50 = lds_pIC50 / np.mean(lds_pIC50) # 원본 코드에는 이게 없는데 이렇게 해야 가중치 간 값의 차이가 좀 생김\n",
    "    # 이거 안하면 0.62, 0.0054 이런식이라 모델이 제대로 가중치 적용을 못하는듯 하여 이렇게 한 줄 추가함\n",
    "\n",
    "    return lds_pIC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f32fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가우시안 노이즈로 증강한 데이터를 가지고 모델 학습 후 CAS_KPBMA_MAP3K5_IC50s.xlsx의 레이블 추가하기 \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LGBMRegressor(\n",
    "            random_state=42, n_estimators=500, min_child_weight=5, n_jobs=-1,\n",
    "            learning_rate = 0.05\n",
    "        )\n",
    "\n",
    "def kfold(model, X_resampled, y_resampled):\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    mse_list, rmse_list, r2_list = [], [], []\n",
    "\n",
    "    # 인덱스 리셋(정렬/정합 문제 방지)\n",
    "    Xr = X_resampled.reset_index(drop=True)\n",
    "    yr = y_resampled.reset_index(drop=True)\n",
    "    w_all = np.asarray(lds(yr), dtype=float)  # 전체에서 만든 가중치라면\n",
    "\n",
    "    for tr_idx, te_idx in kf.split(Xr):\n",
    "        X_train, X_test = Xr.iloc[tr_idx], Xr.iloc[te_idx]\n",
    "        y_train, y_test = yr.iloc[tr_idx], yr.iloc[te_idx]\n",
    "\n",
    "        weight = w_all[tr_idx]                       \n",
    "        model.fit(X_train, y_train, sample_weight=weight)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        mse_list.append(mse)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    print(\"각 Fold의 MSE:\", mse_list)\n",
    "    print(\"평균 MSE:\", np.mean(mse_list))\n",
    "    print(\"각 Fold의 RMSE:\", rmse_list)\n",
    "    print(\"평균 RMSE:\", np.mean(rmse_list))\n",
    "    print(\"각 Fold의 R2:\", r2_list)\n",
    "    print(\"평균 R2:\", np.mean(r2_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "219636c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "synth_matrix: 100%|##########| 1503/1503 [01:36<00:00, 15.55it/s]\n",
      "r_index: 100%|##########| 1499/1499 [00:55<00:00, 26.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "herg_pIC50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 9612, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.650824\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 9613, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.613736\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 9613, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.669643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 9613, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.590713\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 9613, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.589914\n",
      "각 Fold의 MSE: [0.37037429550136225, 0.35563263372277204, 0.3576221021635827, 0.33503759871616234, 0.3554891045395172]\n",
      "평균 MSE: 0.3548311469286793\n",
      "각 Fold의 RMSE: [0.6085838442658187, 0.5963494225056079, 0.5980151353967412, 0.5788243245719398, 0.5962290705253454]\n",
      "평균 RMSE: 0.5956003594530906\n",
      "각 Fold의 R2: [0.9015983501098893, 0.9049481640691767, 0.9038850695799069, 0.9110758075188417, 0.9061978704343088]\n",
      "평균 R2: 0.9055410523424247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "synth_matrix: 100%|##########| 3282/3282 [05:23<00:00, 10.13it/s]\n",
      "r_index: 100%|##########| 1941/1941 [01:47<00:00, 18.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hepg2_pIC50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 18860, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.638381\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 18860, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.415835\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 18860, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.595817\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 18860, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.436917\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 18860, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.438909\n",
      "각 Fold의 MSE: [0.464155851451699, 0.44581336550694645, 0.47989416257901113, 0.463175739882543, 0.4549388772168143]\n",
      "평균 MSE: 0.4615955993274028\n",
      "각 Fold의 RMSE: [0.681289843936998, 0.6676925681082173, 0.6927439372372819, 0.6805701579429876, 0.6744915694186358]\n",
      "평균 RMSE: 0.6793576153288241\n",
      "각 Fold의 R2: [0.8847688098080573, 0.8886602750936334, 0.879078927556374, 0.8842533652165419, 0.8866137784051857]\n",
      "평균 R2: 0.8846750312159586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "synth_matrix: 100%|##########| 632/632 [00:35<00:00, 17.98it/s]\n",
      "r_index: 100%|##########| 128/128 [00:02<00:00, 42.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyp1_pIC50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4249, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -2.379071\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4249, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -2.280384\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4250, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -2.251430\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4250, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -2.207889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4250, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -2.206071\n",
      "각 Fold의 MSE: [0.27588111805785953, 0.2261483189087189, 0.26662331622928864, 0.3097729130591639, 0.23482970500685565]\n",
      "평균 MSE: 0.2626510742523773\n",
      "각 Fold의 RMSE: [0.52524386532149, 0.4755505429591253, 0.5163558039078177, 0.5565724688296789, 0.48459230803517267]\n",
      "평균 RMSE: 0.5116629978106569\n",
      "각 Fold의 R2: [0.9279222621196879, 0.941250128888276, 0.9333482493872658, 0.9211661657562976, 0.9404666777118376]\n",
      "평균 R2: 0.9328306967726728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "synth_matrix: 100%|##########| 926/926 [00:40<00:00, 23.07it/s]\n",
      "r_index: 100%|##########| 246/246 [00:06<00:00, 35.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyp2_pIC50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4838, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.489119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4838, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.732543\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4838, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.531590\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4839, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.516558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4839, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -2.032416\n",
      "각 Fold의 MSE: [0.32723531556556923, 0.3013314381858578, 0.2842889407028582, 0.3096872260361824, 0.32794299341171007]\n",
      "평균 MSE: 0.3100971827804355\n",
      "각 Fold의 RMSE: [0.5720448545049324, 0.5489366431436854, 0.5331875286452771, 0.5564954860878769, 0.5726630714579997]\n",
      "평균 RMSE: 0.5566655167679544\n",
      "각 Fold의 R2: [0.9123375183586769, 0.9205840226212068, 0.9262191869223845, 0.9178596308225985, 0.915674686111527]\n",
      "평균 R2: 0.9185350089672788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "synth_matrix: 100%|##########| 1374/1374 [01:42<00:00, 13.36it/s]\n",
      "r_index: 100%|##########| 353/353 [00:13<00:00, 26.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyp3_pIC50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 7160, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.880693\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 7161, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.701987\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 7161, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.708977\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 7161, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.657448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 7161, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.758228\n",
      "각 Fold의 MSE: [0.4006442895634827, 0.3456027017981179, 0.37002490830367946, 0.36964050642857355, 0.32860379076235624]\n",
      "평균 MSE: 0.36290323937124197\n",
      "각 Fold의 RMSE: [0.6329646827141959, 0.5878798361894358, 0.608296727184751, 0.6079806793217803, 0.5732397323654007]\n",
      "평균 RMSE: 0.6020723315551127\n",
      "각 Fold의 R2: [0.8918943450114174, 0.9074298789561336, 0.899951520602775, 0.9003388448951793, 0.9107999762453397]\n",
      "평균 R2: 0.902082913142169\n"
     ]
    }
   ],
   "source": [
    "def for_ml_train_data(pIC50_name):\n",
    "\ttrain = df_pca[~df_pca[pIC50_name].isnull()]\n",
    "\ttrain = train[[i for i in train.columns if 'pIC50' not in i] + [pIC50_name]]\n",
    "\treturn train\n",
    "\n",
    "pIC_list = ['herg_pIC50', 'hepg2_pIC50', 'cyp1_pIC50', 'cyp2_pIC50', 'cyp3_pIC50']\n",
    "\n",
    "for y_name in pIC_list:\n",
    "\tpIC50_name = y_name\n",
    "\n",
    "\ttrain_data = for_ml_train_data(pIC50_name)\n",
    "\ttrain_data = train_data.reset_index(drop=True)\n",
    "\n",
    "\tdf_gn = iblr.gn(\n",
    "\tdata=train_data, y=y_name)\n",
    "\n",
    "\tX_resampled = df_gn.drop(columns=[y_name])\n",
    "\ty_resampled = df_gn[y_name]\n",
    "\t\t\t\t\t\t\t\t\t\t\t\n",
    "\tprint(y_name)\n",
    "\tkfold(model, X_resampled, y_resampled)\n",
    "\n",
    "\tdf_pca = df_pca.reset_index(drop=True)\n",
    "\tdf = df.reset_index(drop=True)\n",
    "\n",
    "\tpred = model.predict(df_pca[df_pca[y_name].isnull()][[i for i in df_pca.columns if 'pca' in i]])\n",
    "\tdf.loc[df[y_name].isnull(), y_name] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb1c6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccb05be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f644f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# herg_pIC50\n",
    "# 평균 MSE: 0.3548311469286793\n",
    "# 평균 RMSE: 0.5956003594530906\n",
    "# 평균 R2: 0.9055410523424247\n",
    "\n",
    "# hepg2_pIC50\n",
    "# 평균 MSE: 0.4615955993274028\n",
    "# 평균 RMSE: 0.6793576153288241\n",
    "# 평균 R2: 0.8846750312159586\n",
    "\n",
    "# cyp1_pIC50\n",
    "# 평균 MSE: 0.2626510742523773\n",
    "# 평균 RMSE: 0.5116629978106569\n",
    "# 평균 R2: 0.9328306967726728\n",
    "\n",
    "# cyp2_pIC50\n",
    "# 평균 MSE: 0.3100971827804355\n",
    "# 평균 RMSE: 0.5566655167679544\n",
    "# 평균 R2: 0.9185350089672788\n",
    "\n",
    "# cyp3_pIC50\n",
    "# 평균 MSE: 0.36290323937124197\n",
    "# 평균 RMSE: 0.6020723315551127\n",
    "# 평균 R2: 0.902082913142169"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
